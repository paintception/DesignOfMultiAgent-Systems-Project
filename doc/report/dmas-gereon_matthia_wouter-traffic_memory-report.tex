\documentclass[a4paper,hidelinks]{article}
\usepackage{bnaic}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{natbib}

\usepackage{filecontents}
\usepackage{hyperref}
\usepackage{graphicx}


\title{\textbf{\huge Traffic Memory: A Multi Agent System Approach to Traffic Flow Optimization}%
}
\author{
	Gereon Vienken (s2738805) \and
    Matthia Sabatelli (s2847485) \and
    Wouter Reckman (s2231166)
}
\date{}

\pagestyle{empty}

\begin{document}
\ttl
\thispagestyle{empty}

%\bibliography{dmas-gereon_matthia_wouter-traffic_memory-report}


\begin{abstract}
\noindent
In this paper we present a Multi-Agent System simulation of traffic in which 50 agents travel for 10 days in a 7x7 grid where they move from a random starting position to a random assigned destination. In the grid we have created junctions where the agents have to pass through during the travel process in order to make traffic jams occur. This regards the first part of the experiment, in the second one we provide the agents with a memory system in which they are able to remember the most congested roads with a weighted A* path finding algorithm and compare the traffic situation to the previous one in order to see if the general traffic flow improves. 
\end{abstract}


\section{Introduction}
During the last decades it has been shown that travelling by car is still one of the most comfortable and appreciated ways to move through countries. The reasons of this constant growth are several, they go in fact from the always more affordable prices of cars that make every family able to own one car or more to the creation of the European Community that has lead to the elimination of boundaries between countries and has facilitated the trade and exchange of resources between different countries. As a result millions of people suffer everyday from congestion and traffic jams in urban road networks while trying to travel to their daily destinations. This may happen because the existing road networks and the way these are controlled are old and inappropriate and as a consequence unable to regulate the quantity of car traffic of the 21st century but also because the drivers that occupy these road networks are unable to cooperate between each other in order to make the traffic flow more liveable. What's sure about traffic jams is that it has several negative impacts, first of all it makes people's life more difficult then it already actually is, leading to frustration and selfishness in order to avoid them. But there is more, and it regards the ecological impact that traffic jams have on every day's life, the air pollution has in fact reached such high levels in some countries that it has been identified as one of the main reasons of the exacerbation of asthma, allergy and many other respiratory diseases. Part of the air contamination is given by the auto mobile exhausts that combined with certain industrial pollutants produce photochemical reactions that are damaging for humans health \cite{ghose2005assessment}. Even though many people don't think about all these issues traffic has a very important role in our society and this has lead us to the work that is presented in the next sessions.             


\subsection{Problem}
As already mentioned the main problem we try to address regards the inefficiencies in traffic. A lot of research has been done in this field by various scientists and as it will be explained more in detail in the state of the art section the flow of traffic has been modelled under various conditions in order to measure its relative impact. This paper tries to add to this reservoir by trying to understand which possible impact the driver memory of different agents that deal with repeating traffic situations may have. In fact, we all know the situation of drivers that face traffic jams on their daily commute, but what we would like to investigate is how these drivers face jams at the same junction day after day, will they still decide to drive the same route and make the situation on the streets even more worse then it actually is or would they better it by deciding to try their luck of the beaten path the next time? This article tries to get closer to an answer for these questions. 

\subsection{State of the art}
Several research that deals with the optimization of traffic flow may be found in literature and mainly it is possible to divide the approaches that guide this type of research into two sub-fields which both naturally suit the artificial intelligence agent paradigm: on the one side there is research that focuses on modelling the single agents that are on the street; the main idea of this approach is that by modifying their behaviours the whole situation of the traffic will change as a consequence. This approach may be defined as reductionistic since it deals with the single agents on the streets in order to get an overall improvement of the whole traffic flow. On the other side there is research that tries to model the overall behaviour on the streets without directly influencing the single agents, this is done by putting focus on external agents that govern traffic as the most common traffic lights. This last category is for sure the most intuitive and easy to understand one since in everyday life we deal with traffic lights continuously. In fact it doesn't need to be an expert to understand how a traffic light system works. There is in fact a traffic signal timing plan where various traffic phases are coordinated by the traffic light system itself, this is done in order to prevent crashes between traffic phases and ensure the smoothness of the overall traffic flow within the traffic network. As explained in [1] there are various ways in which these kind of systems may work but the most general idea is that there is a fixed-time traffic signal plan management where all the duration of the traffic signals are pre-set in the database and being executed repeatedly. The configurations of he traffic signals durations are done based on some historical traffic statistic gathered for a long period. The setting of the fixed time traffic signal plan is then not changed until the next review on the statistic traffic information is provided. This is a very common approach but as highlighted in the paper a little bit too static, in order to better the way in which the traffic light system works the authors have provided the system with a reinforcement learning algorithm that makes it able to adapt itself to the traffic flow it deals with. This is for sure a possible way to model traffic flow but this paper has been inspired by the first possible approach that was explained before, in fact the main article that guided our work was proposed by Gabel et al. in 2008 \cite{gabel2012cooperative}. In this paper the authors compared two microscopic traffic simulations that regarded two types of possible drivers: one selfish driver model and one selfless driver model. They showed that the selfish driver simply tried to maximize his own speed without caring about the rest of the drivers and the general situation of the roads, doing so the probability that traffic jams occurred was very high since there wasn't any cooperation by the various agents on the streets. On the other side the selfless drivers used a Markov decision model in order to maximize the speed over all cars, doing so it's true that every agent tried to minimize his personal costs but at the same time he does this bearing in mind that there are other agents as well on the streets and is able to find a compromise in order to don't get stacked in the traffic. We were very inspired by this approach that tries to verify the impact of another human trade in traffic simulations. As will be explained more in detail in the next sessions of this paper we decided to provide our agents with a memory system that allowed them to remember situations in which they had to deal with traffic jams, bearing these in mind they are able to come up with different driving strategies that may be a little bit less fast but that optimize the general traffic flow of the streets.
This kind of compromise may be seen in different research papers as mentioned by France et al. \cite{france2003multiagent} coordination between the different agents on the streets is in fact of key importance since it is crucial to maintain a balance between optimized events both at a global level then at a local one. Unfortunately this kind of approach is also very difficult to implement since optimizing local events does not necessarily guarantee a global balance.         

\subsection{New idea}
The new idea our project proposal is to see if memory can actually have an impact on the flow of traffic over longer periods of time. Thinking about this project we came up with the idea that this may also deal with theory of mind but we are not sure at the moment if we will have enough time to also implement a working version that takes this into account. Anyway what we hope is that our implementation can show that with providing the agents with some memory in order to avoid previously encountered situations, the traffic flow over the map will go smoother and that the average travelling speed per car will increase. In contrast to our main reference paper \cite{gabel2012cooperative} we only use selfish agents, but by making them more intelligent to pursue their own goals we hope that as an indirect result they will help other agents in the overall process as well.

\section{Method}
\subsection{Simulation model}
To make our traffic simulation we have defined and implemented the following parameters. A 7x7 grid in which a total of 50 independent agents travel from a random chosen starting point to a random chosen destination. They do this for 10 days without interruption and try to get to their destination as quickly as possible using the A* path finding algorithm. In this grid there are 49 junctions they can travel through which have a certain agent capacity that we have setted to 3, once this limit is reached the traffic gets blocked and traffic jams occur. This scenario is explained in the figure hereafter where the more red the junction gets the more blocked the traffic turns out to be:

\begin{figure}[ht!]
\centering
\includegraphics[width = 0.7\linewidth]{/home/matthia/Scrivania/grid.png}
\caption{Traffic Scenario \label{overflow}}
\end{figure} 


These traffic jams can occur if cars first try to enter a junction from more directions and then will try to leave it simultaneously, this turns the junction into a kind of bottleneck. This aspect of the traffic is on what our whole simulation goes about. At the end of the first 10 days simulation our agents remember the junctions in which the more traffic occurred and in the second part of it they use this information to re-plan their routes in our version of the A* algorithm. This means that the path finding algorithm gives different weights to the various steps it has computed to make an agent get to his destination, in fact if one of these steps corresponds to a high congested junction the algorithm plans a new route in which he tries to avoid it. We have decided to go with a global memory model since on one side it's easier to implement and on the other side it is more human likely since it reflects the fact that these information is actually available for every driver that deals with a very common navigation system. 

\subsection{Experiment design}




metrics: 1) fuel consumption <- article with usable modelling function (vel+accel?)

\section{Results}
\subsection{Experiment findings}
TODO: how do we want to present results? (graphs, avg. flow/speed/fuel/jams)

\subsection{Interpretation of findings}
What's the story? Why is happening what is happening? verwacht: sluiproutegedrag, en ToM nodig om dat te vermijden

\section{Conclusion}
\subsection{Discussion}
\subsection{Relevance}
The intention of this paper was to show, that the use of memory in a repeated traffic situation can improve traffic flow and prevent traffic jams. This information could be used to improve traffic guidance systems like gps. If memory improves the traffic flow even though its just agent independent knowledge, that would mean, that a selfish change in behaviour can still improve the traffic situation as a whole without the need of direct inter-agent communication. If this is not possible it would be necessary for the agents to communicate with one another in order to distribute the traffic intentionally which would require a large amount of work and inter cooperation-cooperation. 
The benefit of an easy solution could guarantee, that improved guiding systems could be produced that by their usage would optimize traffic for everyone. The benefits of optimised traffic are wildly known \cite{france2003multiagent}. Not just that it's bad for your personal health when you come to work with high bloodstream and the intend to murder people, but it's also unproductive for thousands of people to spend hours a day doing nothing. On a global scale, optimising traffic also has the beneficial trade to reduce the carbon emission of the cars, that no longer stand on the streets with running motors. All in all, optimising traffic is a worthwhile attempt to promote peoples health productivity and quality of life. 


\bibliographystyle{plain}
\bibliography{dmas-gereon_matthia_wouter-traffic_memory-report.bib}


\end{document}
