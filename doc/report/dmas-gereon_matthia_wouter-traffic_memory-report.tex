\documentclass[a4paper,hidelinks]{article}
\usepackage{bnaic}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}

\usepackage{filecontents}
\usepackage{hyperref}
\usepackage{graphicx}


\title{\textbf{\huge DMAS Project report\\ <We still don't have a good title :P>}%
}
\author{Gereon Vienken (s2738805) \and
    Matthia Sabatelli (s2847485) \and
    Wouter Reckman (s2231166)
}
\date{}

\pagestyle{empty}

\begin{document}
\ttl
\thispagestyle{empty}

%\bibliography{dmas-gereon_matthia_wouter-traffic_memory-report}


\begin{abstract}
\noindent
In this paper we present a Multi-Agent System simulation of traffic in which 50 agents travel for 10 days in a 7x7 grid where they move from a random starting position to a random assigned destination. In the grid we have created junctions where the agents have to pass through during the travel process in order to make traffic jams occur. This regards the first part of the experiment, in the second one we provide the agents with a memory system in which they are able to remember the most congested roads with a weighted A* path finding algorithm and compare the traffic situation to the previous one in order to see if the general traffic flow improves. 
\end{abstract}


\section{Introduction}
During the last decades it has been shown that travelling by car is still one of the most comfortable and appreciated ways to move through countries. The reasons of this constant growth are several, they go in fact from the always more affordable prices of cars that make every family able to own one car or more to the creation of the European Community that has lead to the elimination of boundaries between countries and has facilitated the trade and exchange of resources between different countries. As a result millions of people suffer everyday from congestion and traffic jams in urban road networks while trying to travel to their daily destinations. This may happen because the existing road networks and the way these are controlled are old and inappropriate and as a consequence unable to regulate the quantity of car traffic of the 21st century but also because the drivers that occupy these road networks are unable to cooperate between each other in order to make the traffic flow more liveable. What's sure about traffic jams is that it has several negative impacts, first of all it makes people's life more difficult then it already actually is, leading to frustration and selfishness in order to avoid them. But there is more, and it regards the ecological impact that traffic jams have on every day's life, the air pollution has in fact reached such high levels in some countries that it has been identified as one of the main reasons of the exacerbation of asthma, allergy and many other respiratory diseases. Part of the air contamination is given by the auto mobile exhausts that combined with certain industrial pollutants produce photochemical reactions that are damaging for humans health [4]. Even though many people don't think about all these issues traffic has a very important role in our society and this has lead us to the work that is presented in the next sessions.             


\subsection{Problem}
As already mentioned the main problem we try to address regards the inefficiencies in traffic. A lot of research has been done in this field by various scientists and as it will be explained more in detail in the state of the art section the flow of traffic has been modelled under various conditions in order to measure its relative impact. This paper tries to add to this reservoir by trying to understand which possible impact the driver memory of different agents that deal with repeating traffic situations may have. In fact, we all know the situation of drivers that face traffic jams on their daily commute, but what we would like to investigate is how these drivers face jams at the same junction day after day, will they still decide to drive the same route and make the situation on the streets even more worse then it actually is or would they better it by deciding to try their luck of the beaten path the next time? This article tries to get closer to an answer for these questions. 

\subsection{State of the art}
Several research that deals with the optimization of traffic flow may be found in literature and mainly it is possible to divide the approaches that guide this type of research into two sub-fields which both naturally suit the artificial intelligence agent paradigm: on the one side there is research that focuses on modelling the single agents that are on the street; the main idea of this approach is that by modifying their behaviours the whole situation of the traffic will change as a consequence. This approach may be defined as reductionistic since it deals with the single agents on the streets in order to get an overall improvement of the whole traffic flow. On the other side there is research that tries to model the overall behaviour on the streets without directly influencing the single agents, this is done by putting focus on external agents that govern traffic as the most common traffic lights. This last category is for sure the most intuitive and easy to understand one since in everyday life we deal with traffic lights continuously. In fact it doesn't need to be an expert to understand how a traffic light system works. There is in fact a traffic signal timing plan where various traffic phases are coordinated by the traffic light system itself, this is done in order to prevent crashes between traffic phases and ensure the smoothness of the overall traffic flow within the traffic network. As explained in [1] there are various ways in which these kind of systems may work but the most general idea is that there is a fixed-time traffic signal plan management where all the duration of the traffic signals are pre-set in the database and being executed repeatedly. The configurations of he traffic signals durations are done based on some historical traffic statistic gathered for a long period. The setting of the fixed time traffic signal plan is then not changed until the next review on the statistic traffic information is provided. This is a very common approach but as highlighted in the paper a little bit too static, in order to better the way in which the traffic light system works the authors have provided the system with a reinforcement learning algorithm that makes it able to adapt itself to the traffic flow it deals with. This is for sure a possible way to model traffic flow but this paper has been inspired by the first possible approach that was explained before, in fact the main article that guided our work was proposed by Gabel et al. in 2008 [3]. In this paper the authors compared two microscopic traffic simulations that regarded two types of possible drivers: one selfish driver model and one selfless driver model. They showed that the selfish driver simply tried to maximize his own speed without caring about the rest of the drivers and the general situation of the roads, doing so the probability that traffic jams occurred was very high since there wasn't any cooperation by the various agents on the streets. On the other side the selfless drivers used a Markov decision model in order to maximize the speed over all cars, doing so it's true that every agent tried to minimize his personal costs but at the same time he does this bearing in mind that there are other agents as well on the streets and is able to find a compromise in order to don't get stacked in the traffic. We were very inspired by this approach that tries to verify the impact of another human trade in traffic simulations. As will be explained more in detail in the next sessions of this paper we decided to provide our agents with a memory system that allowed them to remember situations in which they had to deal with traffic jams, bearing these in mind they are able to come up with different driving strategies that may be a little bit less fast but that optimize the general traffic flow of the streets.
This kind of compromise may be seen in different research papers as mentioned by France et al.[2] coordination between the different agents on the streets is in fact of key importance since it is crucial to maintain a balance between optimized events both at a global level then at a local one. Unfortunately this kind of approach is also very difficult to implement since optimizing local events does not necessarily guarantee a global balance.         

\subsection{New idea}
The new idea our project proposal is to see if memory can actually have an impact on the flow of traffic over longer periods of time. Thinking about this project we came up with the idea that this may also deal with theory of mind but we are not sure at the moment if we will have enough time to also implement a working version that takes this into account. Anyway what we hope is that our implementation can show that with providing the agents with some memory in order to avoid previously encountered situations, the traffic flow over the map will go smoother and that the average travelling speed per car will increase. In contrast to our main reference paper [3] we only use selfish agents, but by making them more intelligent to pursue their own goals we hope that as an indirect result they will help other agents in the overall process as well.

\section{Method}
\subsection{Simulation model}
To make our traffic simulation we have programmed a grid of nodes. Each node represents a junction of streets, the streets are represented by simple lists. Each junction and street are allowed to hold a specific number of cars passing through them with a first-in-first-out schema. A traffic jam in this situation would occur if cars would first try to enter a junction from more directions and then will try to leave it, turning that junction into a kind of bottleneck. This aspect of the traffic is on what our whole simulation goes about. The cars on the road a re-controlled by separate agents, which give them a spawn location and a destination, these agents can then determine the fastest route with an weighted a* implementation algorithm. The weights of a* can be influenced by the memory of previous traffic jams the agents have encountered. This memory consists of a global array that holds the roads where traffic jams have occurred in previous situations. For now we have decided to go with a global memory model since on side it's easier to implement and on the other side it reflects the fact that these information are available for every driver that deals with a navigation system. 

\subsection{Experiment design}
metrics: 1) fuel consumption <- article with usable modelling function (vel+accel?)

\section{Results}
\subsection{Experiment findings}
TODO: how do we want to present results? (graphs, avg. flow/speed/fuel/jams)

\subsection{Interpretation of findings}
What's the story? Why is happening what is happening? verwacht: sluiproutegedrag, en ToM nodig om dat te vermijden

\section{Conclusion}
\subsection{Discussion}
\subsection{Relevance}


\bibliographystyle{plain}


\begin{thebibliography}{8}


\bibitem{1} Chin et al. (2005) Q-Learning Based Traffic Optimization in Management of Signal Timing Plan.
\bibitem{2} France et al. (2003). A Multi-Agent System for Optimizing Urban Traffic.
\bibitem{3} Gabel et al. (2012). The cooperative driver: Multi-agent learning for preventing traffic jams.
\bibitem{4} Ghose et al. (2005). Assessment of the status of urban air pollution and its impact on human health.

\end{thebibliography}

\begin{filecontents}{dmas-gereon_matthia_wouter-traffic_memory-report.bib}
@article{gabel2012cooperative,
  title={The cooperative driver: Multi-agent learning for preventing traffic jams},
  author={Gabel, Thomas and Riedmiller, Martin},
  journal={International journal of traffic and transportation engineering},
  volume={1},
  number={4},
  pages={67--76},
  year={2012},
  publisher={Scientific \& Academic Publishing}
}
\end{filecontents}

\end{document}
